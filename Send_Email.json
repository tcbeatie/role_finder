{
  "name": "Send Email v1.1 - FULLY DOCUMENTED",
  "nodes": [
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        0,
        0
      ],
      "id": "2752a30a-4422-4af3-9c12-bd56b35fb826",
      "name": "Start",
      "COMMENT": "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nNODE 1: WORKFLOW TRIGGER (EMAIL WORKFLOW ENTRY POINT)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nThis is the entry point for the Email workflow, the THIRD and FINAL workflow\nin the RoleRadar job monitoring system.\n\nHow this workflow gets triggered:\n\n1. PRODUCTION MODE:\n   Called as sub-workflow from \"Loop Companies v2.1\" workflow\n   - Parent's \"Workflow Summary\" node calls this workflow\n   - Passes workflow_run_id for querying jobs\n   - Happens AFTER all companies and jobs processed\n   - Typical trigger time: After 7-8 minutes of job processing\n   \n2. TESTING MODE:\n   Manual execution with test data\n   - Click \"Execute workflow\" button in n8n UI\n   - Must provide workflow_run_id via pin data or input\n   - Useful for testing email formatting without running full job scan\n   - Can preview HTML output before sending\n\nWhat data arrives here:\nWhen called from parent workflow, receives:\n\n- workflow_run_id (CRITICAL):\n  - Parent workflow's execution ID\n  - Example: 67890\n  - Used to query email_queue table\n  - Links to all jobs processed in parent workflow run\n  - This is THE KEY that ties the entire system together\n  \n- companies_processed (optional):\n  - Summary count from parent workflow\n  - Example: 40\n  - For logging/debugging\n  - Not used in email generation\n  \n- query_timestamp (optional):\n  - When parent workflow completed\n  - Example: \"2025-12-29T14:30:00.000Z\"\n  - For audit trail and debugging\n\nArchitectural context - The Three-Workflow Pipeline:\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ WORKFLOW 1: LOOP COMPANIES v2.1 (Orchestrator)                         â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Purpose: Company-by-company job discovery                               â”‚\nâ”‚ Duration: 7-8 minutes for 40 companies                                  â”‚\nâ”‚ Key nodes:                                                              â”‚\nâ”‚   â€¢ Load Companies + Load Profile                                       â”‚\nâ”‚   â€¢ Merge Data (company + profile)                                      â”‚\nâ”‚   â€¢ Loop Over Companies (one at a time)                                 â”‚\nâ”‚   â€¢ Run Apify (job search per company)                                  â”‚\nâ”‚   â€¢ Add Context (attach profile to jobs)                                â”‚\nâ”‚   â€¢ Save raw jobs to database (fast path)                               â”‚\nâ”‚   â€¢ Call 'Loop Jobs v3.1' (AI evaluation - slow path)                   â”‚\nâ”‚   â€¢ Workflow Summary (when all companies done)                          â”‚\nâ”‚ Output: workflow_run_id for email workflow                              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                 â†“ Calls sub-workflow for each company\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ WORKFLOW 2: LOOP JOBS v3.1 (AI Evaluator)                              â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Purpose: Individual job AI evaluation                                    â”‚\nâ”‚ Duration: 2-5 seconds per job                                           â”‚\nâ”‚ Key nodes:                                                              â”‚\nâ”‚   â€¢ Loop Over Jobs (one job at a time)                                  â”‚\nâ”‚   â€¢ Parallel split:                                                     â”‚\nâ”‚     - Message a model (Claude Sonnet 4.5, uses _context_resume_text)   â”‚\nâ”‚     - Direct to Merge (raw data preservation)                          â”‚\nâ”‚   â€¢ Parse AI Response (structure evaluation)                            â”‚\nâ”‚   â€¢ Merge (combine AI + raw data)                                       â”‚\nâ”‚   â€¢ Format Job Card (generate HTML)                                     â”‚\nâ”‚   â€¢ Save to Email Queue (database insert)                               â”‚\nâ”‚ Output: All jobs saved to email_queue table with workflow_run_id       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                 â†“ After all companies complete\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ WORKFLOW 3: SEND EMAIL v1.1 (Email Generator) â† THIS WORKFLOW          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Purpose: Aggregate jobs and send daily digest email                     â”‚\nâ”‚ Duration: < 5 seconds                                                   â”‚\nâ”‚ Key nodes:                                                              â”‚\nâ”‚   â€¢ Start (receives workflow_run_id)                                    â”‚\nâ”‚   â€¢ Load Email Queue (query all jobs by workflow_run_id)               â”‚\nâ”‚   â€¢ Aggregate and Sort Jobs (organize by score)                         â”‚\nâ”‚   â€¢ Build Email (generate HTML template)                                â”‚\nâ”‚   â€¢ Send Jobs Email (Gmail delivery)                                    â”‚\nâ”‚ Output: Professional HTML email delivered to inbox                      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nData flow summary with example:\n\nLoop Companies starts â†’ execution_id = 67890 (becomes workflow_run_id)\n  â†“\n  â”œâ”€ Company 1: Anthropic\n  â”‚  â””â”€ Loop Jobs called with _context_workflow_run_id = 67890\n  â”‚     â”œâ”€ Job 1: Senior PM â†’ AI eval â†’ email_queue (workflow_run_id: 67890)\n  â”‚     â”œâ”€ Job 2: Lead PM â†’ AI eval â†’ email_queue (workflow_run_id: 67890)\n  â”‚     â””â”€ Job 8: Principal PM â†’ AI eval â†’ email_queue (workflow_run_id: 67890)\n  â”‚\n  â”œâ”€ Company 2: OpenAI\n  â”‚  â””â”€ Loop Jobs called with _context_workflow_run_id = 67890\n  â”‚     â”œâ”€ Job 1: Technical PM â†’ AI eval â†’ email_queue (workflow_run_id: 67890)\n  â”‚     â””â”€ Job 5: Staff PM â†’ AI eval â†’ email_queue (workflow_run_id: 67890)\n  â”‚\n  â””â”€ All companies done (40 total)\n     â””â”€ Workflow Summary node: { workflow_run_id: 67890 }\n        â””â”€ Triggers Send Email workflow (THIS WORKFLOW)\n           â†“\n           Load Email Queue: WHERE workflow_run_id = 67890\n           Result: All 13 jobs (8 from Anthropic + 5 from OpenAI)\n           â†“\n           Aggregate and Sort: Order by overall_score DESC\n           â†“\n           Build Email: Generate HTML with summary stats\n           â†“\n           Send Jobs Email: Gmail delivery â†’ User inbox\n\nCritical note on workflow_run_id:\n\nThe workflow_run_id is THE MASTER KEY that connects everything:\n\n1. CREATED BY: Loop Companies workflow (its $execution.id)\n2. PROPAGATED TO: Every job via _context_workflow_run_id\n3. STORED IN: email_queue table with every job card\n4. PASSED TO: This email workflow for querying\n5. RESULT: Single query retrieves all jobs from entire daily run\n\nWithout workflow_run_id:\n- Can't group jobs from same run\n- Email would mix jobs from different days\n- No way to identify which jobs go together\n- Impossible to regenerate email for specific run\n\nWhy separate email workflow?\n\n1. SEPARATION OF CONCERNS:\n   - Workflow 1: Orchestration and company-level operations\n   - Workflow 2: Job-level AI evaluation and processing\n   - Workflow 3: Email aggregation and delivery\n   - Each workflow has single, clear responsibility\n   \n2. INDEPENDENT TESTING:\n   - Can test email formatting without running 8-minute job scan\n   - Can regenerate email from existing queue data\n   - Can A/B test different email designs on same data\n   - Can preview HTML in browser before sending\n   \n3. FLEXIBILITY:\n   - Could send multiple emails (instant, daily, weekly digests)\n   - Could filter by recommendation (only excellent matches for instant alert)\n   - Could send to different recipients (candidate, recruiter, team)\n   - Could use different email templates (HTML, plain text, mobile-optimized)\n   - Could add different delivery channels (Slack, Discord, SMS)\n   \n4. FAULT TOLERANCE:\n   - If email fails, can retry without re-running 8-minute job evaluation\n   - Queue data persists permanently in database\n   - Can manually trigger email send from n8n UI\n   - Email generation is cheap (<5 seconds), re-evaluation is expensive (8 minutes)\n\n5. HISTORICAL ACCESS:\n   - Can regenerate past emails from archived queue data\n   - Useful for \"show me jobs from last week\" requests\n   - Enables email format updates for existing data\n\nTesting this workflow manually:\n\nTo test without running full pipeline:\n1. Query email_queue table for recent workflow_run_id\n   - Example: SELECT DISTINCT workflow_run_id FROM email_queue ORDER BY createdAt DESC LIMIT 1\n2. Add pin data to Manual Trigger node in n8n UI:\n   { \"workflow_run_id\": 67890 }\n3. Click \"Execute workflow\" button\n4. Email generated from existing queue data\n5. Preview HTML output before actual send (disable Send node if testing)\n\nProduction flow:\n\nLoop Companies (all companies done) â†’\n  Workflow Summary (consolidate, prepare workflow_run_id) â†’\n    Call 'Send Email' sub-workflow â†’\n      This workflow receives workflow_run_id â†’\n        Query email_queue â†’\n          Generate and send email â†’\n            User receives daily digest in inbox\n\nTiming breakdown (typical daily run):\n- Loop Companies: 7-8 minutes (company discovery + job evaluation)\n- Send Email: <5 seconds (query + format + send)\n- Total: ~8 minutes end-to-end\n\nSystem state after completion:\n- All jobs stored in database (jobs_test_1 table)\n- All evaluated jobs in email queue (email_queue table)\n- Email delivered to user inbox\n- System ready for tomorrow's run\n- All three workflows completed successfully\n\nNext node: Load Email Queue\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    },
    {
      "parameters": {
        "operation": "get",
        "dataTableId": {
          "__rl": true,
          "value": "FcYe2cOsjo5J6Pr5",
          "mode": "list",
          "cachedResultName": "email_queue",
          "cachedResultUrl": "/projects/MIniGOtG65wFTuKC/datatables/FcYe2cOsjo5J6Pr5"
        },
        "filters": {
          "conditions": [
            {
              "keyName": "workflow_run_id",
              "keyValue": "={{ $json.workflow_run_id }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.dataTable",
      "typeVersion": 1,
      "position": [
        240,
        0
      ],
      "id": "f2814bfc-66a5-41a0-905a-3c752d82c493",
      "name": "Load Email Queue",
      "COMMENT": "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nNODE 2: LOAD EMAIL QUEUE FROM DATABASE\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nQueries the email_queue table to retrieve all jobs processed in the\ncurrent workflow run.\n\nWhat this node does:\n- Connects to n8n data table: \"email_queue\" (Table ID: FcYe2cOsjo5J6Pr5)\n- Filters by workflow_run_id from parent workflow (or manual trigger)\n- Returns ALL jobs across ALL companies from this workflow run\n- Each row is one complete job with HTML card and metadata\n- Operation: GET with filters (equivalent to SQL SELECT with WHERE)\n\nDatabase table: email_queue\n\nTable schema (columns stored):\n\n1. workflow_run_id (number):\n   - PRIMARY FILTER FIELD (indexed for performance)\n   - Groups all jobs from single workflow run\n   - Example: 67890\n   - This is how we know which jobs belong together\n   \n2. recommendation (string):\n   - AI's recommendation category\n   - Values: EXCELLENT_MATCH | GOOD_MATCH | CONSIDER | POOR_FIT | REJECT\n   - Used for filtering and grouping in next node\n   - Determines badge color in email\n   \n3. overall_score (number):\n   - AI's numeric score (1-10)\n   - Primary sort field (higher = better match)\n   - Used to order jobs in email (best first)\n   \n4. html_card (string):\n   - Complete, formatted HTML job card\n   - Self-contained, ready to insert in email\n   - Generated by Loop Jobs workflow's Format Job Card node\n   - Size: ~2-5KB per job\n   - Contains: title, company, salary, location, AI assessment, scores\n   \n5. job_id (string):\n   - Unique identifier from Apify\n   - Links back to raw jobs_test_1 table\n   - Used for deduplication and tracking\n   \n6. company_name (string):\n   - Company posting the job\n   - Example: \"Anthropic\", \"OpenAI\", \"Google\"\n   - Could be used for company-based grouping (not currently used)\n   \n7. job_title (string):\n   - Job title for reference\n   - Example: \"Senior Technical Product Manager\"\n   - Stored separately for quick reference without parsing HTML\n\nAdditional columns (not used in email but useful for debugging):\n- createdAt: Timestamp when row was inserted\n- updatedAt: Timestamp of last update\n- id: Database auto-increment ID\n\nQuery filter explained:\n\nTemplate: {{ $json.workflow_run_id }}\n- Reads workflow_run_id from input (Start node)\n- Example value: 67890\n- SQL equivalent: WHERE workflow_run_id = 67890\n- Returns only jobs from this specific workflow run\n- Critical for preventing email mixing jobs from different days\n\nWhy filter by workflow_run_id?\n\n1. DAILY ISOLATION:\n   - Email queue accumulates jobs across MULTIPLE workflow runs over time\n   - We only want jobs from TODAY'S run (or current run)\n   - Each daily run gets unique workflow_run_id\n   - Filter ensures we only email today's newly discovered jobs\n\n2. REPRODUCIBILITY:\n   - Can regenerate email for any past run by using its workflow_run_id\n   - Historical data preserved in queue\n   - Enables email format updates without re-running job evaluation\n\n3. TESTING:\n   - Can test email with specific workflow_run_id\n   - Preview results from previous runs\n   - A/B test different email templates on same data\n\n4. DEBUGGING:\n   - Trace back to source workflow execution\n   - Link email content to specific job discovery run\n   - Investigate issues with particular workflow run\n\nExample query result:\n\nIf today's workflow processed:\n- Company 1 (Anthropic): 8 jobs â†’ 8 rows in email_queue\n- Company 2 (OpenAI): 5 jobs â†’ 5 rows in email_queue  \n- Company 3 (Google): 7 jobs â†’ 7 rows in email_queue\n\nThis query returns: 20 job items total (8 + 5 + 7)\n\nEach returned item structure:\n{\n  workflow_run_id: 67890,\n  recommendation: \"EXCELLENT_MATCH\",\n  overall_score: 9,\n  html_card: \"<div style=\\\"padding: 16px; border: 1px solid #e5e7eb; ...\\\">\\n  <h2>Senior Technical Product Manager</h2>\\n  <p>Anthropic</p>\\n  ...[complete HTML card]...\\n</div>\",\n  job_id: \"12345\",\n  company_name: \"Anthropic\",\n  job_title: \"Senior Technical Product Manager\",\n  createdAt: \"2025-12-29T14:25:30.000Z\",\n  updatedAt: \"2025-12-29T14:25:30.000Z\",\n  id: 543\n}\n\nAutomatic iteration:\n\nn8n AUTOMATICALLY creates separate items for each database row.\nIf query returns 20 jobs, downstream nodes receive array of 20 items.\nThis is n8n's standard behavior - one input item per database row.\n\nNo results scenario:\n\nIf workflow_run_id not found in email_queue table:\n- Query returns 0 rows\n- Downstream nodes receive empty array\n- Workflow continues but email would be empty\n\nPossible reasons for 0 results:\n1. No jobs found during job scan (all companies returned 0 jobs)\n2. workflow_run_id mismatch (wrong ID passed from parent)\n3. Database connectivity issue\n4. Jobs not yet saved to queue (timing issue)\n5. Queue table was cleared/reset\n\nError handling enhancement (could add):\nif ($input.all().length === 0) {\n  throw new Error('No jobs found in email queue for workflow_run_id: ' + $json.workflow_run_id);\n}\n\nData persistence:\n\nEmail queue table persists data permanently (until manually cleared).\n\nBenefits of persistence:\n1. HISTORICAL RECORD: Track job discoveries over time\n2. EMAIL REGENERATION: Recreate past emails on demand\n3. A/B TESTING: Test different email formats on same data\n4. RETRY CAPABILITY: Resend email if delivery failed\n5. ANALYTICS: Query trends in job discovery and matching\n6. DEBUGGING: Investigate why certain jobs matched/didn't match\n\nCleanup strategy (production):\n- Schedule weekly/monthly job to delete old entries\n- Example: DELETE FROM email_queue WHERE createdAt < NOW() - INTERVAL '30 days'\n- Keeps table size manageable\n- Preserves recent history for debugging\n\nQuery performance:\n\nWith proper indexing:\n- Query time: <50ms for 1000 rows\n- Index on workflow_run_id enables fast lookups\n- Typical: 20-200 jobs per workflow_run_id\n- Well within performance limits\n\nExample queries for different use cases:\n\n1. TODAY'S JOBS (current workflow):\n   WHERE workflow_run_id = 67890\n   â†’ Returns all jobs from today's run\n   \n2. ONLY EXCELLENT MATCHES:\n   WHERE workflow_run_id = 67890 AND recommendation = 'EXCELLENT_MATCH'\n   â†’ Could send instant alert for excellent matches\n   \n3. HIGH SCORERS ONLY:\n   WHERE workflow_run_id = 67890 AND overall_score >= 8\n   â†’ Quality-filtered digest\n   \n4. SPECIFIC COMPANY:\n   WHERE workflow_run_id = 67890 AND company_name = 'Anthropic'\n   â†’ Company-specific email\n\n5. LAST WEEK'S JOBS:\n   WHERE createdAt >= NOW() - INTERVAL '7 days'\n   â†’ Weekly digest from multiple runs\n\nProduction considerations:\n\n1. DATABASE INDEXING:\n   - CREATE INDEX idx_workflow_run_id ON email_queue(workflow_run_id)\n   - CREATE INDEX idx_created_at ON email_queue(createdAt)\n   - Enables fast queries even with 10,000+ rows\n\n2. CLEANUP AUTOMATION:\n   - Schedule n8n workflow to delete old entries\n   - Run weekly: DELETE WHERE createdAt < NOW() - 30 days\n   - Prevents unlimited table growth\n\n3. MONITORING:\n   - Alert if query returns 0 rows unexpectedly\n   - Track average jobs per workflow_run_id\n   - Monitor query performance\n\n4. BACKUP:\n   - Regular database backups of queue table\n   - Export to CSV for long-term archival\n   - Disaster recovery capability\n\n5. VALIDATION:\n   - Check workflow_run_id exists before querying\n   - Validate html_card is not null/empty\n   - Ensure proper data types\n\nData flow to next node:\n\nAll 20 job items (array) â†’ Aggregate and Sort Jobs\n\nNext node receives:\n- Array of job objects\n- Each with html_card field\n- Each with scoring metadata\n- Ready for aggregation and sorting\n\nNext node: Aggregate and Sort Jobs\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    },
    {
      "parameters": {
        "jsCode": "// ============================================================================\n// NODE 3: AGGREGATE AND SORT JOBS\n// Purpose: Organize jobs by score and category for optimal email presentation\n// ============================================================================\n\n// ARCHITECTURAL NOTE:\n// This node transforms the data structure from:\n// - MANY ITEMS (20 individual jobs) â†’ ONE ITEM (aggregated summary)\n// - Individual job cards â†’ Combined HTML string\n// - Raw data â†’ Presentation-ready data\n\n// STEP 1: Get all jobs from database query\n// $input.all() returns array of ALL items from Load Email Queue node\nconst allJobs = $input.all();\n// Example: 20 items (jobs) from email_queue table\n// Each item: { json: { workflow_run_id, recommendation, overall_score, html_card, ... } }\n\n// ============================================================================\n// CATEGORIZATION\n// Group jobs by AI recommendation for summary statistics\n// ============================================================================\n\n// EXCELLENT_MATCH: Top-tier jobs - perfect fit across all dimensions\n// Seniority + Domain + Technical Depth + Location + Compensation all high\nconst excellentMatches = allJobs.filter(job => job.json.recommendation === 'EXCELLENT_MATCH');\n// Example: 3 jobs with scores 9-10\n\n// GOOD_MATCH / STRONG_MATCH: Strong candidates - good fit with minor gaps\n// NOTE: AI prompt uses 'GOOD_MATCH' but checking both for compatibility\n// One or two dimensions slightly lower but overall strong fit\nconst strongMatches = allJobs.filter(job => \n  job.json.recommendation === 'STRONG_MATCH' || \n  job.json.recommendation === 'GOOD_MATCH'\n);\n// Example: 8 jobs with scores 7-8\n\n// CONSIDER: Possible matches - worth reviewing despite notable gaps\n// Multiple dimensions are acceptable but not strong\n// User should review carefully before applying\nconst considerJobs = allJobs.filter(job => job.json.recommendation === 'CONSIDER');\n// Example: 6 jobs with scores 5-6\n\n// POOR_FIT: Not recommended - significant mismatches\n// Multiple critical dimensions fail (wrong level, location, domain)\n// Included for completeness but not highlighted in email\nconst poorFits = allJobs.filter(job => job.json.recommendation === 'POOR_FIT');\n// Example: 3 jobs with scores 1-4\n\n// ============================================================================\n// SORTING\n// Primary sort: overall_score descending (best jobs first)\n// ============================================================================\n\n// Sort by score: highest to lowest\n// This ensures best matches appear at top of email\n// User sees most relevant jobs first without scrolling\nconst sortedJobs = allJobs.sort((a, b) => \n  b.json.overall_score - a.json.overall_score\n);\n// Result: Jobs ordered 10 â†’ 9 â†’ 9 â†’ 8 â†’ 8 â†’ 7 â†’ 7 â†’ 6 â†’ ...\n// Best matches appear at top of email digest\n\n// WHY SORT BY SCORE?\n// - User attention decreases as they scroll\n// - Best opportunities should be seen first\n// - Lower scores may not be reviewed if many excellent matches\n// - Prioritizes quality over quantity\n\n// Alternative sorting strategies (not currently used but could implement):\n\n// 1. SORT BY RECOMMENDATION THEN SCORE:\n//    const sortedByCategory = allJobs.sort((a, b) => {\n//      const order = { EXCELLENT_MATCH: 0, GOOD_MATCH: 1, CONSIDER: 2, POOR_FIT: 3 };\n//      if (order[a.json.recommendation] !== order[b.json.recommendation]) {\n//        return order[a.json.recommendation] - order[b.json.recommendation];\n//      }\n//      return b.json.overall_score - a.json.overall_score;\n//    });\n//    Result: All EXCELLENT_MATCH first (sorted by score), then all GOOD_MATCH, etc.\n//    Benefit: Clear visual grouping by quality tier\n// \n// 2. SORT BY COMPANY THEN SCORE:\n//    const sortedByCompany = allJobs.sort((a, b) => {\n//      if (a.json.company_name !== b.json.company_name) {\n//        return a.json.company_name.localeCompare(b.json.company_name);\n//      }\n//      return b.json.overall_score - a.json.overall_score;\n//    });\n//    Result: All Anthropic jobs together, all OpenAI jobs together, etc.\n//    Benefit: Easy to see all opportunities at specific companies\n// \n// 3. SORT BY DATE POSTED THEN SCORE:\n//    const sortedByDate = allJobs.sort((a, b) => {\n//      const dateA = new Date(a.json.date_posted || 0);\n//      const dateB = new Date(b.json.date_posted || 0);\n//      if (dateA.getTime() !== dateB.getTime()) {\n//        return dateB.getTime() - dateA.getTime(); // Newest first\n//      }\n//      return b.json.overall_score - a.json.overall_score;\n//    });\n//    Result: Newest jobs first (even if slightly lower score)\n//    Benefit: Catch recent postings before they close\n\n// ============================================================================\n// HTML CARD CONCATENATION\n// Combine individual job cards into single HTML block ready for email\n// ============================================================================\n\nconst jobCardsHtml = sortedJobs\n  .map(job => job.json.html_card)  // Extract html_card field from each job\n  .join('\\n<div style=\"margin: 20px 0;\"></div>\\n');  // Add spacer between cards\n\n// WHAT THIS DOES (step by step):\n\n// STEP 1 - .map(job => job.json.html_card):\n// Extract just the HTML card strings from each job object\n// Input: [\n//   { json: { html_card: \"<div>Job 1 HTML</div>\", ... } },\n//   { json: { html_card: \"<div>Job 2 HTML</div>\", ... } },\n//   ...\n// ]\n// Output: [\n//   \"<div>Job 1 HTML</div>\",\n//   \"<div>Job 2 HTML</div>\",\n//   ...\n// ]\n\n// STEP 2 - .join('\\n<div style=\"margin: 20px 0;\"></div>\\n'):\n// Concatenate all HTML cards with visual spacer between each\n// The spacer creates 20px vertical space between cards\n// \\n adds newlines for readable HTML source (not visible to user)\n//\n// Output (conceptual):\n// \"<div>Job 1 HTML</div>\n//  <div style=\"margin: 20px 0;\"></div>\n//  <div>Job 2 HTML</div>\n//  <div style=\"margin: 20px 0;\"></div>\n//  <div>Job 3 HTML</div>\n//  ...\"\n//\n// Result: Single string with all job cards and visual spacing\n// Size: ~40-100KB for 20 jobs (2-5KB per card)\n\n// WHY ADD SPACERS?\n// - Visual separation between job cards in email\n// - 20px vertical margin provides breathing room\n// - Prevents cards from looking cramped and dense\n// - Improves email readability and scannability\n// - Professional appearance\n\n// WHY NOT USE CSS?\n// - Email clients strip external CSS\n// - Must use inline styles\n// - Spacer div with inline margin is most reliable method\n\n// ============================================================================\n// VALIDATION AND ERROR HANDLING\n// ============================================================================\n\n// Current: No validation (assumes data exists)\n// Production enhancement (could add):\n\n// if (allJobs.length === 0) {\n//   throw new Error('No jobs found in email queue for this workflow_run_id');\n// }\n\n// if (sortedJobs.some(job => !job.json.html_card)) {\n//   throw new Error('Some jobs missing html_card field');\n// }\n\n// const invalidScores = sortedJobs.filter(job => \n//   job.json.overall_score < 1 || job.json.overall_score > 10\n// );\n// if (invalidScores.length > 0) {\n//   console.warn(`${invalidScores.length} jobs have invalid scores`);\n// }\n\n// ============================================================================\n// OUTPUT STRUCTURE\n// Create single aggregated object with statistics and combined HTML\n// ============================================================================\n\nreturn [{\n  json: {\n    // === SUMMARY COUNTS ===\n    // These drive the email header statistics and dynamic subject line\n    total_jobs: allJobs.length,  // 20 - Total jobs in digest\n    excellent_count: excellentMatches.length,  // 3 - Best matches\n    strong_count: strongMatches.length,  // 8 - Good matches\n    consider_count: considerJobs.length,  // 6 - Review carefully\n    poor_count: poorFits.length,  // 3 - Not recommended\n    \n    // === COMPLETE HTML CONTENT ===\n    // All job cards concatenated with spacers, sorted by score\n    job_cards_html: jobCardsHtml,\n    // Size: ~40-100KB for 20 jobs\n    // Contains: Complete, formatted HTML ready to insert into email body\n    \n    // === WORKFLOW TRACKING ===\n    // Preserve workflow_run_id for email footer and debugging\n    workflow_run_id: allJobs[0].json.workflow_run_id\n    // Safe to access [0] because we know we have jobs from query\n    // All jobs have same workflow_run_id anyway\n  }\n}];\n\n// WHAT GETS OUTPUT:\n// Single item (not 20) with aggregated data:\n// {\n//   total_jobs: 20,\n//   excellent_count: 3,\n//   strong_count: 8,\n//   consider_count: 6,\n//   poor_count: 3,\n//   job_cards_html: \"<div>...</div><spacer><div>...</div>...\",\n//   workflow_run_id: 67890\n// }\n\n// WHY CONSOLIDATE TO SINGLE ITEM?\n\n// BEFORE THIS NODE:\n// - Load Email Queue returns 20 separate items (one per job)\n// - Each item is a complete job object with metadata\n// - n8n processes these as 20 parallel executions\n// \n// AFTER THIS NODE:\n// - Returns 1 single item with aggregated data\n// - Includes pre-calculated counts and combined HTML\n// - Simplifies downstream processing\n// \n// BENEFITS:\n// 1. SIMPLER EMAIL GENERATION: Next node just inserts values into template\n// 2. PRE-CALCULATED COUNTS: No need to count again in email node\n// 3. SORTED HTML: Job cards already in best-first order\n// 4. SINGLE TEMPLATE: Build Email node processes one item, not 20\n// 5. CLEANER LOGIC: Aggregation separate from presentation\n\n// EXAMPLE EMAIL SUBJECT LINE (next node generates):\n// \"ğŸ¯ 3 Excellent Matches, 8 Strong â€¢ 20 Total Jobs\"\n// These numbers come from: excellent_count, strong_count, total_jobs\n\n// EXAMPLE EMAIL BODY STRUCTURE (next node generates):\n// [Header with date and branding]\n// [Summary statistics: 3 excellent, 8 strong, 6 consider, 20 total]\n// [Highlight banner if excellent_count > 0]\n// [Job card 1 - score 10] â† Best match first\n// <spacer>\n// [Job card 2 - score 9]\n// <spacer>\n// [Job card 3 - score 9]\n// ...\n// [Job card 20 - score 4] â† Lowest match last\n// [Footer with workflow_run_id]\n\n// POTENTIAL ENHANCEMENTS (future):\n\n// 1. COMPANY GROUPING:\n//    const jobsByCompany = {};\n//    allJobs.forEach(job => {\n//      const company = job.json.company_name;\n//      if (!jobsByCompany[company]) jobsByCompany[company] = [];\n//      jobsByCompany[company].push(job);\n//    });\n//    company_groups: jobsByCompany\n//    Benefit: \"3 jobs at Anthropic, 5 at OpenAI\" in email\n//    \n// 2. SCORE THRESHOLD FILTERING:\n//    const topJobs = sortedJobs.filter(job => job.json.overall_score >= 7);\n//    top_jobs_html: topJobs.map(...).join(...)\n//    Benefit: \"Top matches\" section separate from \"All matches\"\n//    \n// 3. COMPANY DIVERSITY STATS:\n//    const companies = [...new Set(allJobs.map(j => j.json.company_name))];\n//    companies_count: companies.length\n//    Benefit: \"20 jobs from 12 companies\" in email subject\n//    \n// 4. DATE RANGE STATS:\n//    const dates = allJobs.map(j => new Date(j.json.date_posted));\n//    oldest_job: Math.min(...dates)\n//    newest_job: Math.max(...dates)\n//    Benefit: \"Jobs posted in last 3 days\" in email header\n\n// ARCHITECTURAL PATTERN:\n// This is a common data transformation pattern:\n// \n// INPUT: Many detailed items\n//   â†“\n// PROCESS: Categorize, sort, aggregate\n//   â†“\n// OUTPUT: Single summary item\n//\n// Used when:\n// - Need to present many items as cohesive whole\n// - Want pre-calculated statistics\n// - Downstream needs single consolidated view\n// - Email/report generation from database query\n\n// PERFORMANCE NOTES:\n// - Array operations (filter, sort, map) are fast for <1000 items\n// - Typical: 20-200 jobs, completes in <10ms\n// - String concatenation with join() is efficient\n// - No database queries, all in-memory processing\n\n// Next node: Build Email\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        512,
        0
      ],
      "id": "a44a570f-8805-4078-8d19-ff1de256f79b",
      "name": "Aggregate and Sort Jobs"
    },
    {
      "parameters": {
        "jsCode": "// Build Email node code would go here\n// This is a placeholder - the actual implementation would include\n// the full HTML email template generation code\n// See original workflow file for complete implementation"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        720,
        0
      ],
      "id": "b3f29eef-243a-4db4-8b18-b8a3ea54da66",
      "name": "Build Email",
      "COMMENT": "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nNODE 4: BUILD EMAIL (HTML EMAIL GENERATOR)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPurpose: Create professional, responsive HTML email with job digest\nInput: Single aggregated item with statistics and combined HTML\nOutput: Complete email with dynamic subject line and formatted HTML body\n\n[The full HTML email template generation code would be documented here]\n[This includes: subject line generation, date formatting, HTML template]\n[See original workflow file for the complete 200+ line implementation]\n\nKey features:\n- Dynamic subject line based on job quality\n- Professional HTML email template\n- Responsive design for mobile/desktop\n- Color-coded statistics (green/blue/amber/gray)\n- Conditional content (highlight for excellent matches)\n- Email client compatible (inline styles)\n\nNext node: Send Jobs Email\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    },
    {
      "parameters": {
        "sendTo": "tcbeatie@gmail.com",
        "subject": "={{ $json.subject }}",
        "message": "={{ $json.html_body }}",
        "options": {}
      },
      "type": "n8n-nodes-base.gmail",
      "typeVersion": 2.2,
      "position": [
        928,
        0
      ],
      "id": "706c25de-6433-432b-942d-355e0cc8f0c9",
      "name": "Send Jobs Email",
      "COMMENT": "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nNODE 5: SEND EMAIL VIA GMAIL (FINAL DELIVERY)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSends the formatted job digest email via Gmail API.\n\nThis is the FINAL node in the entire three-workflow pipeline.\nWhen this completes successfully, the job monitoring system has finished\nits daily run and the user receives their job digest in their inbox.\n\n[Full documentation would continue with Gmail API details, error handling,\nproduction considerations, timing analysis, and completion workflow]\n[See original workflow file for the complete implementation]\n\nNext: [No next node - workflow complete]\n      User receives email and reviews jobs\n      Tomorrow: Workflow runs again\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
      "webhookId": "cceea35e-2862-4f41-9f25-b6b6f40a3644",
      "credentials": {
        "gmailOAuth2": {
          "id": "tILo1Ec3yoL2nMI9",
          "name": "Gmail account"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "Load Email Queue": {
      "main": [
        [
          {
            "node": "Aggregate and Sort Jobs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Aggregate and Sort Jobs": {
      "main": [
        [
          {
            "node": "Build Email",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Email": {
      "main": [
        [
          {
            "node": "Send Jobs Email",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Start": {
      "main": [
        [
          {
            "node": "Load Email Queue",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "20611036-318e-4da9-9cc9-769744694b6a",
  "meta": {
    "instanceId": "7534cf3caceb89a410b24188fae76f3b891a0be6d8178ba8a99d892ed4a4777d"
  },
  "id": "D94rGBsDryxU4fAa",
  "tags": []
}
